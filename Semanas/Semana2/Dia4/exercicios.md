# üéØ Exerc√≠cios Pr√°ticos - RAG Avan√ßado com Vector Databases

## üìã Objetivo

Consolidar conhecimento atrav√©s de exerc√≠cios pr√°ticos progressivos sobre:
- Embeddings e representa√ß√£o vetorial
- Vector databases (Chroma)
- Busca sem√¢ntica
- Sistema RAG avan√ßado completo

**Tempo estimado total: 20 minutos (parte da fase de Consolida√ß√£o)**

---

## üìö Antes de Come√ßar

### Pr√©-requisitos:
- ‚úÖ `template.py` completo e funcionando
- ‚úÖ Chroma vector store criado com documentos
- ‚úÖ Leitura de `GUIA_RAG_AVANCADO.md` completa

### Arquivos de Refer√™ncia:
- `GUIA_RAG_AVANCADO.md` - Teoria e implementa√ß√£o
- `exemplo_referencia.py` - C√≥digo completo funcionando
- `template.py` - Seu c√≥digo com TODOs completados

---

## üèãÔ∏è Exerc√≠cio 1: Embeddings B√°sicos (5min)

### Objetivo
Entender como embeddings representam texto e calcular similaridade.

### Tarefa
Crie um script que:
1. Cria embeddings de 4 textos diferentes
2. Calcula similaridade entre pares de textos
3. Identifica quais textos s√£o mais similares

### C√≥digo Base
```python
from langchain_community.embeddings import HuggingFaceEmbeddings
from sklearn.metrics.pairwise import cosine_similarity

# Criar modelo de embeddings
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# Textos para testar
textos = [  
    "O cachorro late no quintal",
    "O c√£o est√° latindo",
    "O gato mia na casa",
    "O computador est√° ligado"
]

# TODO 1: Criar embeddings de todos os textos
# embs = [embeddings.embed_query(t) for t in textos]

# TODO 2: Calcular similaridade entre texto 1 e todos os outros
# for i in range(1, len(textos)):
#     sim = cosine_similarity([embs[0]], [embs[i]])[0][0]
#     print(f"Similaridade '{textos[0]}' vs '{textos[i]}': {sim:.4f}")

# TODO 3: Identificar qual texto √© mais similar ao texto 1
```

### Crit√©rios de Aceita√ß√£o
- [ x] Embeddings criados para todos os textos
- [ x] Similaridade calculada corretamente
- [ X] Texto 2 ("O c√£o est√° latindo") √© o mais similar ao texto 1 ‚úÖ
- [ X] Texto 4 ("O computador...") √© o menos similar ao texto 1 ‚úÖ

### Resposta Esperada
```
Similaridade 'O cachorro late no quintal' vs 'O c√£o est√° latindo': 0.5428
Similaridade 'O cachorro late no quintal' vs 'O gato mia na casa': 0.5161
Similaridade 'O cachorro late no quintal' vs 'O computador est√° ligado': 0.4778
Similaridade 'O cachorro late no quintal' vs 'A vaca est√° na casa': 0.4299
Similaridade 'O cachorro late no quintal' vs 'O pato est√° no quintal': 0.6952

Texto mais similar: "O c√£o est√° latindo" (sin√¥nimo!)
```

### Dica
- Se similaridade n√£o faz sentido: Verificar se modelo est√° carregado corretamente
- Embeddings s√£o arrays grandes (384 n√∫meros), normaliza√ß√£o √© importante

---

## üèãÔ∏è Exerc√≠cio 2: FAISS Vector Store e Busca Sem√¢ntica (10min)

### Objetivo
Praticar cria√ß√£o de vector store e comparar busca literal vs sem√¢ntica.

### Tarefa
1. Criar vector store com documentos de teste
2. Realizar buscas usando palavras exatas
3. Realizar buscas usando sin√¥nimos
4. Comparar resultados

### C√≥digo Base
```python
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document

# Criar embeddings
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# Documentos de teste
docs = [
    Document(page_content="O carro vermelho √© muito r√°pido", metadata={"id": 1}),
    Document(page_content="O autom√≥vel azul √© econ√¥mico", metadata={"id": 2}),
    Document(page_content="O ve√≠culo verde √© espa√ßoso", metadata={"id": 3}),
    Document(page_content="O computador est√° quebrado", metadata={"id": 4}),
    Document(page_content="A bicicleta √© um meio de transporte", metadata={"id": 5})
]

# TODO 1: Criar vector store
# vectorstore = Chroma.from_documents(
#     documents=docs,
#     embedding=embeddings,
#     persist_directory="./chroma_exercicio2"
# )

# TODO 2: Criar retriever
# retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# TODO 3: Buscar com palavra exata
print("=== Busca 1: Palavra exata 'carro' ===")
# results = retriever.invoke("carro")
# for doc in results:
#     print(f"- {doc.page_content}")

# TODO 4: Buscar com sin√¥nimo 've√≠culo'
print("\n=== Busca 2: Sin√¥nimo 've√≠culo' ===")
# results = retriever.invoke("ve√≠culo")
# for doc in results:
#     print(f"- {doc.page_content}")

# TODO 5: Buscar com conceito 'transporte r√°pido'
print("\n=== Busca 3: Conceito 'transporte r√°pido' ===")
# results = retriever.invoke("transporte r√°pido")
# for doc in results:
#     print(f"- {doc.page_content}")
```

### Crit√©rios de Aceita√ß√£o
- [ X] Vector store criado com sucesso
- [ X] Busca 1 ("carro"): Retorna docs 1, 2, 3 (sobre carros/autom√≥veis/ve√≠culos) ‚úÖ
- [ X] Busca 2 ("ve√≠culo"): Retorna docs 1, 2, 3 mesmo sem palavra "ve√≠culo" em alguns ‚úÖ
- [ X] Busca 3 ("transporte r√°pido"): Retorna doc 1 (carro r√°pido) no topo ‚úÖ
- [ X] Doc 4 (computador) nunca aparece nas buscas sobre transporte ‚úÖ

### Resultado Esperado
```
Busca 1 (carro):
- O carro vermelho √© muito r√°pido ‚úÖ
- O autom√≥vel azul √© econ√¥mico ‚úÖ (sin√¥nimo!)
- O ve√≠culo verde √© espa√ßoso ‚úÖ (sin√¥nimo!)

Busca 2 (ve√≠culo):
- O ve√≠culo verde √© espa√ßoso ‚úÖ
- O carro vermelho √© muito r√°pido ‚úÖ (entendeu que carro=ve√≠culo!)
- O autom√≥vel azul √© econ√¥mico ‚úÖ (entendeu que autom√≥vel=ve√≠culo!)

Busca 3 (transporte r√°pido):
- O carro vermelho √© muito r√°pido ‚úÖ (perfeito!)
- A bicicleta √© um meio de transporte ‚úÖ (transporte, mas n√£o r√°pido)
- O ve√≠culo verde √© espa√ßoso ‚úÖ (transporte, mas n√£o sobre velocidade)
```

### An√°lise
**Por que busca sem√¢ntica √© superior:**
- ‚úÖ Entende sin√¥nimos (carro = autom√≥vel = ve√≠culo)
- ‚úÖ Entende conceitos (transporte r√°pido ‚Üí carro r√°pido)
- ‚úÖ N√£o se limita a palavras exatas
- ‚úÖ Ordena por relev√¢ncia sem√¢ntica

---

## üèãÔ∏è Exerc√≠cio 3: RAG Avan√ßado Completo (5min)

### Objetivo
Integrar tudo: embeddings + vector store + LLM em sistema RAG completo.

### Tarefa
Usar o vector store do Exerc√≠cio 2 para criar RAG chain e responder perguntas.

### C√≥digo Base
```python
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv
import os

load_dotenv()

# Usar vector store do Exerc√≠cio 2
# (ou criar novo se preferir)

# TODO 1: Configurar LLM
# llm = ChatGroq(
#     model="llama-3.1-70b-versatile",
#     api_key=os.getenv("GROQ_API_KEY")
# )

# TODO 2: Criar prompt template
# template = """Responda baseado apenas no contexto:
#
# Contexto:
# {context}
#
# Pergunta: {question}
#
# Resposta:"""
#
# prompt = ChatPromptTemplate.from_template(template)

# TODO 3: Fun√ß√£o para formatar documentos
# def format_docs(docs):
#     return "\n\n".join([doc.page_content for doc in docs])

# TODO 4: Criar RAG chain
# rag_chain = (
#     {"context": retriever | format_docs, "question": RunnablePassthrough()}
#     | prompt
#     | llm
#     | StrOutputParser()
# )

# TODO 5: Testar com perguntas
perguntas = [
    "Qual ve√≠culo √© r√°pido?",
    "Fale sobre autom√≥veis econ√¥micos",
    "Existe algum transporte espa√ßoso?"
]

# for pergunta in perguntas:
#     print(f"\n‚ùì {pergunta}")
#     resposta = rag_chain.invoke(pergunta)
#     print(f"üí° {resposta}")
```

### Crit√©rios de Aceita√ß√£o
- [ X] RAG chain criada com sucesso
- [ X] Pergunta 1: Responde "carro vermelho" (identificou "r√°pido") ‚úÖ
- [ X] Pergunta 2: Responde "autom√≥vel azul" (entendeu sin√¥nimo) ‚úÖ
- [ X] Pergunta 3: Responde "ve√≠culo verde" (identificou "espa√ßoso") ‚úÖ
- [ X] Respostas baseadas no contexto, n√£o inventadas ‚úÖ

### Resultado Esperado
```
‚ùì Qual ve√≠culo √© r√°pido?
üí° O carro vermelho √© muito r√°pido.

‚ùì Fale sobre autom√≥veis econ√¥micos
üí° O autom√≥vel azul √© econ√¥mico.

‚ùì Existe algum transporte espa√ßoso?
üí° Sim, o ve√≠culo verde √© espa√ßoso.
```

### Valida√ß√£o
**Sistema RAG est√° funcionando se:**
- ‚úÖ Retriever encontra documentos relevantes (busca sem√¢ntica)
- ‚úÖ LLM usa apenas contexto fornecido (n√£o inventa)
- ‚úÖ Respostas s√£o precisas e baseadas nos documentos
- ‚úÖ Sistema entende sin√¥nimos e conceitos

**Resultado esperado:**
- FAISS geralmente 2-5x mais r√°pido em buscas
- Chroma mais f√°cil de usar (persist autom√°tico)

### Desafio 2: RAG com M√∫ltiplos Documentos (20min)

**Objetivo:** Trabalhar com vector store grande e queries complexas.

**Tarefa:**
1. Adicionar 20+ documentos sobre diferentes t√≥picos
2. Criar RAG system
3. Fazer queries que requerem informa√ß√£o de m√∫ltiplos docs
4. Avaliar qualidade das respostas

**Exemplo de query complexa:**
"Compare motores a gasolina com motores el√©tricos em termos de economia e meio ambiente"

**Crit√©rio de sucesso:**
- RAG deve buscar docs sobre gasolina E el√©tricos
- Resposta deve comparar ambos
- Informa√ß√£o de m√∫ltiplos chunks deve ser integrada

### Desafio 3: Embeddings Multil√≠ngues (15min)

**Objetivo:** Testar embeddings com documentos em portugu√™s.

**Tarefa:**
1. Usar modelo multil√≠ngue: `paraphrase-multilingual-MiniLM-L12-v2`
2. Criar docs em portugu√™s
3. Comparar com modelo em ingl√™s (`all-MiniLM-L6-v2`)
4. Avaliar qual funciona melhor para portugu√™s

**Hip√≥tese:**
- Modelo multil√≠ngue deve ter melhor performance em portugu√™s
- Mas pode ser mais lento

---

## üìä Resumo dos Exerc√≠cios

| Exerc√≠cio | Tempo | Foco | Crit√©rio de Sucesso |
|-----------|-------|------|---------------------|
| 1. Embeddings | 5min | Similaridade | Calcular similaridade corretamente |
| 2. Chroma + Busca | 10min | Vector DB | Busca sem√¢ntica funciona com sin√¥nimos |
| 3. RAG Completo | 5min | Integra√ß√£o | RAG responde queries corretamente |
| **Total** | **20min** | **Consolida√ß√£o** | **Sistema RAG funcionando** |

---

## ‚úÖ Checklist de Valida√ß√£o

Ap√≥s completar os exerc√≠cios, voc√™ deve ser capaz de:

### Conhecimento Te√≥rico:
- [ X] Explicar o que s√£o embeddings
- [ X] Explicar como vector databases funcionam
- [ X] Explicar diferen√ßa entre busca literal e sem√¢ntica
- [ ] Explicar quando usar Chroma vs FAISS

### Habilidades Pr√°ticas:
- [ X] Criar embeddings de textos
- [ X] Calcular similaridade entre embeddings
- [ X] Configurar FAISS vector store
- [ X] Criar retriever sem√¢ntico
- [ X] Construir RAG chain completa com LCEL
- [ X] Comparar RAG b√°sico vs avan√ßado

### Compet√™ncias:
- [ X] Escolher chunk_size apropriado
- [ X] Debugar problemas com embeddings
- [ X] Otimizar n√∫mero de documentos (k) retornados
- [ X] Avaliar qualidade de busca sem√¢ntica

---

## üéØ Pr√≥ximos Passos

Ap√≥s completar estes exerc√≠cios:

1. **Revisar `journal.md`:**
   - Documentar o que aprendeu
   - Anotar dificuldades encontradas
   - Registrar insights importantes

2. **Comparar com Dia 3:**
   - Executar mesmas queries em RAG b√°sico (Dia 3)
   - Executar mesmas queries em RAG avan√ßado (Dia 4)
   - Documentar diferen√ßas observadas

3. **Preparar para Dia 5:**
   - Revisar conceitos de RAG avan√ßado
   - Pensar em como RAG pode ser usado como ferramenta
   - Ler sobre Agents (preview do Dia 5)

---

## üí° Dicas Finais

### Se travar em algum exerc√≠cio:
1. **Consultar `GUIA_RAG_AVANCADO.md`** se√ß√£o correspondente
2. **Ver `exemplo_referencia.py`** c√≥digo completo
3. **Comparar com `template.py`** sua implementa√ß√£o
4. **Testar partes isoladamente** (embeddings ‚Üí vector store ‚Üí RAG)

### Debugging:
```python
# Verificar embeddings
emb = embeddings.embed_query("teste")
print(f"Dimens√µes: {len(emb)}")  # Deve ser 384

# Verificar vector store
print(f"Docs no vector store: {vectorstore._collection.count()}")

# Verificar retriever
docs = retriever.invoke("teste")
print(f"Docs encontrados: {len(docs)}")
```

### Performance:
- Primeira execu√ß√£o demora (download de modelo + cria√ß√£o de √≠ndice)
- Execu√ß√µes seguintes s√£o r√°pidas (usa cache)
- Se muito lento: Reduzir n√∫mero de documentos ou usar modelo menor

---

**Bom trabalho nos exerc√≠cios! üöÄ**

**√öltima atualiza√ß√£o:** 4 Dez 2025

