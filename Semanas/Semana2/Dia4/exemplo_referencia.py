#!/usr/bin/env python3
"""
RAG Avan√ßado com Vector Databases - Exemplo Completo

Este arquivo cont√©m um exemplo completo e funcional de RAG avan√ßado usando:
- Embeddings (HuggingFace sentence-transformers)
- Chroma vector database para busca sem√¢ntica
- RAG chain completa com LCEL

Use este arquivo como refer√™ncia ao trabalhar no template.py
Cada se√ß√£o est√° comentada para facilitar o entendimento.

Autor: Plano de Desenvolvimento 2 Meses Web + IA
Data: 4 Dez 2025
"""

# ============================================================================
# SE√á√ÉO 1: IMPORTS
# ============================================================================
# Por que precisamos destes imports:
# - ChatGroq: LLM para gerar respostas
# - ChatPromptTemplate: Criar templates de prompts
# - RunnablePassthrough: Passar dados atrav√©s da chain
# - StrOutputParser: Extrair string do output do LLM
# - Chroma: Vector database para busca sem√¢ntica
# - HuggingFaceEmbeddings: Modelo de embeddings gratuito
# - TextLoader: Carregar documentos de texto
# - RecursiveCharacterTextSplitter: Dividir documentos em chunks
# - dotenv: Carregar vari√°veis de ambiente
# - os: Acessar vari√°veis de ambiente

from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
import os

# ============================================================================
# SE√á√ÉO 2: CONFIGURA√á√ÉO
# ============================================================================
# PASSO 1: Carregar vari√°veis de ambiente
print("="*70)
print("RAG AVAN√áADO COM VECTOR DATABASES - EXEMPLO COMPLETO")
print("="*70)

load_dotenv()  # Carrega arquivo .env na raiz do projeto

# PASSO 2: Verificar se API key est√° dispon√≠vel
if not os.getenv("GROQ_API_KEY"):
    raise ValueError("GROQ_API_KEY n√£o encontrada no .env")

print("\n‚úÖ Vari√°veis de ambiente carregadas")

# ============================================================================
# SE√á√ÉO 3: CRIAR MODELO DE EMBEDDINGS
# ============================================================================
# Por que: Embeddings s√£o representa√ß√µes vetoriais de texto que capturam
# significado sem√¢ntico. Textos similares t√™m embeddings pr√≥ximos.
#
# Modelo escolhido: all-MiniLM-L6-v2
# - 384 dimens√µes (leve e r√°pido)
# - Treinado em ingl√™s (funciona razoavelmente em portugu√™s)
# - Gratuito (HuggingFace)

print("\n" + "-"*70)
print("CRIANDO MODELO DE EMBEDDINGS")
print("-"*70)

embeddings = HuggingFaceEmbeddings(
    model_name="all-MiniLM-L6-v2",  # Modelo leve e r√°pido
    model_kwargs={'device': 'cpu'},  # Usar CPU (trocar para 'cuda' se tiver GPU)
    encode_kwargs={'normalize_embeddings': True}  # Normalizar vetores
)

print("‚úÖ Modelo de embeddings criado: all-MiniLM-L6-v2")
print(f"   Dimens√µes: 384")

# DEMONSTRA√á√ÉO: Criar embeddings de exemplo
print("\nüìä Demonstra√ß√£o de Embeddings:")
textos_exemplo = [
    "O carro √© r√°pido",
    "O autom√≥vel √© veloz",
    "O computador √© lento"
]

print("\nTextos de exemplo:")
for i, texto in enumerate(textos_exemplo):
    print(f"{i+1}. '{texto}'")

# Criar embeddings
embs_exemplo = [embeddings.embed_query(t) for t in textos_exemplo]

# Calcular similaridade (usando cosine similarity manualmente)
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

sim_1_2 = cosine_similarity([embs_exemplo[0]], [embs_exemplo[1]])[0][0]
sim_1_3 = cosine_similarity([embs_exemplo[0]], [embs_exemplo[2]])[0][0]

print(f"\nüìè Similaridades:")
print(f"   'carro' vs 'autom√≥vel': {sim_1_2:.4f} (similares! ‚úÖ)")
print(f"   'carro' vs 'computador': {sim_1_3:.4f} (diferentes ‚úÖ)")
print("   ‚Üí Embeddings capturam significado sem√¢ntico!")

# ============================================================================
# SE√á√ÉO 4: CARREGAR E PROCESSAR DOCUMENTOS
# ============================================================================
# Reutilizando conhecimento do Dia 3
# PASSO 1: Carregar documento de texto
# PASSO 2: Dividir em chunks menores

print("\n" + "-"*70)
print("CARREGANDO E PROCESSANDO DOCUMENTOS")
print("-"*70)

# Criar documento de exemplo se n√£o existir
documento_exemplo = """# Carros e Autom√≥veis

Um carro, tamb√©m chamado de autom√≥vel ou ve√≠culo, √© um meio de transporte motorizado.

## Tipos de Motores

### Motor a Gasolina
O motor a gasolina √© um dos mais comuns. Funciona atrav√©s da combust√£o interna, 
onde a gasolina √© misturada com ar e queimada nos cilindros. √â eficiente para 
uso urbano e oferece boa acelera√ß√£o.

### Motor Diesel
O motor diesel √© mais econ√¥mico que o motor a gasolina. Utiliza combust√≠vel diesel 
e funciona atrav√©s de alta compress√£o. √â comum em ve√≠culos de carga e transporte 
pesado devido ao seu torque elevado.

### Motor El√©trico
O motor el√©trico √© o mais moderno. Funciona com baterias recarreg√°veis e n√£o 
emite poluentes. Carros el√©tricos s√£o silenciosos e muito eficientes em termos 
de energia. S√£o o futuro do transporte sustent√°vel.

## Componentes Principais

### Transmiss√£o
A transmiss√£o transfere a pot√™ncia do motor para as rodas. Pode ser manual 
ou autom√°tica. Transmiss√µes modernas t√™m m√∫ltiplas marchas para efici√™ncia.

### Sistema de Freios
Os freios s√£o essenciais para seguran√ßa. Podem ser a disco ou a tambor. 
Freios modernos incluem sistema ABS para evitar travamento das rodas.

### Suspens√£o
A suspens√£o absorve impactos e mant√©m o conforto. Sistemas modernos 
ajustam-se automaticamente para diferentes condi√ß√µes de estrada.
"""

# Salvar documento de exemplo
with open("documento_carros.txt", "w", encoding="utf-8") as f:
    f.write(documento_exemplo)

print("‚úÖ Documento de exemplo criado: documento_carros.txt")

# Carregar documento
loader = TextLoader("documento_carros.txt", encoding="utf-8")
docs = loader.load()

print(f"‚úÖ Documento carregado: {len(docs)} arquivo(s)")

# Dividir em chunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,  # Tamanho de cada chunk
    chunk_overlap=50,  # Overlap entre chunks para manter contexto
    length_function=len,
    separators=["\n\n", "\n", " ", ""]  # Ordem de separadores
)

chunks = text_splitter.split_documents(docs)
print(f"‚úÖ Documento dividido: {len(chunks)} chunks")

# Mostrar exemplo de chunk
print(f"\nüìÑ Exemplo de Chunk (primeiros 200 caracteres):")
print(f"   {chunks[0].page_content[:200]}...")

# ============================================================================
# SE√á√ÉO 5: CRIAR VECTOR STORE COM CHROMA
# ============================================================================
# Por que Chroma: Vector database local, simples e gratuito
# Ideal para desenvolvimento e testes
#
# O que acontece:
# 1. Cada chunk √© convertido em embedding (vetor)
# 2. Embeddings s√£o armazenados em √≠ndice otimizado
# 3. √çndice permite busca r√°pida por similaridade

print("\n" + "-"*70)
print("CRIANDO VECTOR STORE COM CHROMA")
print("-"*70)

# Criar vector store
# IMPORTANTE: Primeira execu√ß√£o demora (cria embeddings de todos os chunks)
# Execu√ß√µes futuras s√£o r√°pidas (carrega do disco)
vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embeddings,
    persist_directory="./chroma_db"  # Pasta para persistir dados
)

print(f"‚úÖ Vector store criado com sucesso!")
print(f"   Documentos indexados: {len(chunks)}")
print(f"   Persistido em: ./chroma_db")

# ============================================================================
# SE√á√ÉO 6: CRIAR RETRIEVER SEM√ÇNTICO
# ============================================================================
# Retriever: Componente que busca documentos relevantes
# search_type="similarity": Busca por similaridade sem√¢ntica
# k=3: Retorna os 3 documentos mais relevantes

print("\n" + "-"*70)
print("CRIANDO RETRIEVER SEM√ÇNTICO")
print("-"*70)

retriever = vectorstore.as_retriever(
    search_type="similarity",  # Busca por similaridade
    search_kwargs={"k": 3}  # Retornar 3 documentos mais relevantes
)

print("‚úÖ Retriever configurado")
print("   Tipo de busca: Sem√¢ntica (embeddings)")
print("   Documentos por query: 3")

# DEMONSTRA√á√ÉO: Testar retriever com query sobre sin√¥nimos
print("\nüìä Demonstra√ß√£o de Busca Sem√¢ntica:")
query_teste = "ve√≠culo veloz"  # Usando sin√¥nimos
print(f"\nQuery: '{query_teste}'")
print("   (Note: documento usa 'carro', 'autom√≥vel', n√£o 've√≠culo')")

docs_encontrados = retriever.invoke(query_teste)
print(f"\n‚úÖ Encontrados {len(docs_encontrados)} documentos relevantes:")

for i, doc in enumerate(docs_encontrados):
    print(f"\n--- Documento {i+1} ---")
    print(doc.page_content[:150] + "...")

print("\n   ‚Üí Busca sem√¢ntica encontrou docs relevantes mesmo sem palavra exata!")

# ============================================================================
# SE√á√ÉO 7: CONFIGURAR LLM
# ============================================================================
# Usar Groq com modelo Llama 3.1 70B
# Por que: R√°pido, gratuito, qualidade excelente

print("\n" + "-"*70)
print("CONFIGURANDO LLM")
print("-"*70)

llm = ChatGroq(
    model="llama-3.1-70b-versatile",
    api_key=os.getenv("GROQ_API_KEY"),
    temperature=0  # Determin√≠stico (mesma resposta para mesma query)
)

print("‚úÖ LLM configurado: Groq Llama 3.1 70B")

# ============================================================================
# SE√á√ÉO 8: CRIAR PROMPT TEMPLATE
# ============================================================================
# Prompt instrui o LLM a:
# - Usar apenas o contexto fornecido
# - Admitir quando n√£o sabe
# - Ser objetivo e claro

print("\n" + "-"*70)
print("CRIANDO PROMPT TEMPLATE")
print("-"*70)

template = """Voc√™ √© um assistente especializado em responder perguntas baseado em contexto fornecido.

IMPORTANTE:
- Use APENAS as informa√ß√µes do contexto abaixo
- Se a resposta n√£o estiver no contexto, diga: "N√£o encontrei essa informa√ß√£o no contexto fornecido."
- Seja objetivo e claro
- Cite partes relevantes do contexto quando poss√≠vel

Contexto:
{context}

Pergunta: {question}

Resposta detalhada:"""

prompt = ChatPromptTemplate.from_template(template)

print("‚úÖ Prompt template criado")

# ============================================================================
# SE√á√ÉO 9: CRIAR RAG CHAIN COM LCEL
# ============================================================================
# RAG Chain: Retrieval (busca) + Augmented (aumenta prompt) + Generation (gera resposta)
#
# Fluxo:
# 1. Retriever busca documentos relevantes
# 2. format_docs formata documentos em string
# 3. Prompt template √© preenchido com context + question
# 4. LLM gera resposta baseada no prompt
# 5. StrOutputParser extrai string da resposta

print("\n" + "-"*70)
print("CRIANDO RAG CHAIN COM LCEL")
print("-"*70)

# Fun√ß√£o auxiliar para formatar documentos
def format_docs(docs):
    """
    Formata lista de documentos em string √∫nica.
    
    Args:
        docs: Lista de documentos retornados pelo retriever
        
    Returns:
        str: Documentos concatenados com quebras de linha
    """
    return "\n\n".join([doc.page_content for doc in docs])

# Criar RAG chain usando LCEL (LangChain Expression Language)
rag_chain = (
    {
        "context": retriever | format_docs,  # Busca documentos e formata
        "question": RunnablePassthrough()     # Passa pergunta direto
    }
    | prompt          # Aplica template de prompt
    | llm            # Gera resposta com LLM
    | StrOutputParser()  # Extrai string do output
)

print("‚úÖ RAG Chain criada com sucesso!")
print("\nFluxo da chain:")
print("   1. Query ‚Üí Retriever (busca sem√¢ntica)")
print("   2. Docs relevantes ‚Üí format_docs")
print("   3. Context + Question ‚Üí Prompt Template")
print("   4. Prompt ‚Üí LLM")
print("   5. LLM output ‚Üí StrOutputParser ‚Üí Resposta final")

# ============================================================================
# SE√á√ÉO 10: TESTAR RAG CHAIN
# ============================================================================
# Testar com diferentes tipos de queries:
# 1. Query direta (palavra exata no documento)
# 2. Query com sin√¥nimos (testar busca sem√¢ntica)
# 3. Query conceitual (testar entendimento de contexto)

print("\n" + "="*70)
print("TESTANDO RAG AVAN√áADO COM BUSCA SEM√ÇNTICA")
print("="*70)

queries = [
    "Como funciona o motor a gasolina?",
    "Qual tipo de motor √© mais econ√¥mico?",
    "Fale sobre ve√≠culos el√©tricos",  # Sin√¥nimo: ve√≠culo = carro
    "O que √© transmiss√£o autom√°tica?"
]

for query in queries:
    print(f"\n{'-'*70}")
    print(f"‚ùì Pergunta: {query}")
    print(f"{'-'*70}")
    
    # Invocar RAG chain
    resposta = rag_chain.invoke(query)
    
    print(f"\nüí° Resposta:")
    print(resposta)

# ============================================================================
# SE√á√ÉO 11: RAG CHAIN COM FONTES (BONUS)
# ============================================================================
# Vers√£o melhorada que retorna resposta + documentos fonte
# √ötil para rastreabilidade e debugging

print("\n" + "="*70)
print("BONUS: RAG COM FONTES (RASTREABILIDADE)")
print("="*70)

# Chain que retorna resposta + fontes
rag_chain_com_fontes = (
    {
        "context": retriever,  # Retorna docs completos (n√£o formata ainda)
        "question": RunnablePassthrough()
    }
    | (lambda x: {
        "resposta": (
            {"context": format_docs(x["context"]), "question": x["question"]}
            | prompt | llm | StrOutputParser()
        ),
        "fontes": x["context"]
    })
)

# Testar
query_exemplo = "Como funciona o motor el√©trico?"
print(f"\n‚ùì Pergunta: {query_exemplo}")
print(f"{'-'*70}")

resultado = rag_chain_com_fontes.invoke(query_exemplo)

print(f"\nüí° Resposta:")
print(resultado['resposta'])

print(f"\nüìö Fontes ({len(resultado['fontes'])} documentos):")
for i, doc in enumerate(resultado['fontes']):
    print(f"\n{i+1}. {doc.page_content[:200]}...")

# ============================================================================
# SE√á√ÉO 12: COMPARA√á√ÉO COM RAG B√ÅSICO
# ============================================================================
# Demonstrar diferen√ßa entre RAG b√°sico (BM25) e RAG avan√ßado (embeddings)

print("\n" + "="*70)
print("COMPARA√á√ÉO: RAG B√ÅSICO vs RAG AVAN√áADO")
print("="*70)

print("\nüìä Teste de Sin√¥nimos:")
print("-" * 70)

# Query com sin√¥nimo
query_sinonimo = "Fale sobre autom√≥veis movidos a eletricidade"
#                       ‚Üì sin√¥nimos ‚Üì
# Documento real: "carro", "motor el√©trico"

print(f"\nQuery: '{query_sinonimo}'")
print("\nPalavras-chave na query: 'autom√≥veis', 'eletricidade'")
print("Palavras no documento: 'carro', 'motor el√©trico'")
print("\nRAG B√°sico (BM25): ‚ùå N√£o encontraria (palavras diferentes)")
print("RAG Avan√ßado (Embeddings): ‚úÖ Encontra (entende significado)")

# Testar
resposta_sinonimo = rag_chain.invoke(query_sinonimo)
print(f"\nüí° Resposta do RAG Avan√ßado:")
print(resposta_sinonimo)

# ============================================================================
# CONCLUS√ÉO
# ============================================================================
print("\n" + "="*70)
print("CONCLUS√ÉO")
print("="*70)

print("""
‚úÖ Sistema RAG Avan√ßado implementado com sucesso!

üìö O que aprendemos:
1. Embeddings capturam significado sem√¢ntico
2. Vector databases permitem busca eficiente por similaridade
3. Chroma √© simples e eficaz para desenvolvimento
4. Busca sem√¢ntica √© superior a busca literal
5. RAG chain integra retrieval + gera√ß√£o perfeitamente

üéØ Vantagens do RAG Avan√ßado:
- ‚úÖ Entende sin√¥nimos
- ‚úÖ Busca por significado, n√£o apenas palavras
- ‚úÖ Mais relevante que busca literal
- ‚úÖ Escal√°vel para muitos documentos
- ‚úÖ Production-ready

üìà Pr√≥ximos passos:
- Dia 5: Usar RAG avan√ßado como ferramenta de Agents
- Experimentar FAISS para melhor performance
- Testar com documentos maiores e mais complexos
- Explorar embeddings multil√≠ngues para portugu√™s
""")

print("="*70)
print("FIM DO EXEMPLO")
print("="*70)

