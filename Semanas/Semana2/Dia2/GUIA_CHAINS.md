# üîó Guia Completo: Chains e LangChain Expression Language (LCEL)

Este guia explica como criar chains (cadeias) de opera√ß√µes no LangChain usando LCEL, a sintaxe moderna e poderosa do framework.

---

## üìö √çndice

1. [O que s√£o Chains?](#o-que-s√£o-chains)
2. [LangChain Expression Language (LCEL)](#langchain-expression-language-lcel)
3. [Chains Sequenciais](#chains-sequenciais)
4. [Chains Condicionais](#chains-condicionais)
5. [Chains Paralelas](#chains-paralelas)
6. [Composi√ß√£o de Chains](#composi√ß√£o-de-chains)
7. [Streaming com Chains](#streaming-com-chains)
8. [Boas Pr√°ticas](#boas-pr√°ticas)

---

## O que s√£o Chains?

### Conceito

Uma **Chain** √© uma sequ√™ncia de opera√ß√µes conectadas que processam dados de forma sequencial ou paralela. No contexto do LangChain, chains conectam LLMs, prompts, parsers e outras opera√ß√µes.

### Por que usar Chains?

**Sem Chains (c√≥digo manual):**
```python
# C√≥digo verboso e dif√≠cil de manter
prompt = "Gere um resumo sobre Python"
response1 = llm.invoke(prompt)
formatted = format_response(response1.content)
final = translate(formatted, "pt")
```

**Com Chains:**
```python
# C√≥digo declarativo e reutiliz√°vel
chain = prompt | llm | format_response | translate
final = chain.invoke({"input": "Gere um resumo sobre Python"})
```

**Vantagens:**
- ‚úÖ **Composi√ß√£o:** Reutilizar chains em outras chains
- ‚úÖ **Legibilidade:** C√≥digo mais limpo e declarativo
- ‚úÖ **Manutenibilidade:** F√°cil de modificar e debugar
- ‚úÖ **Streaming:** Suporte nativo a respostas incrementais
- ‚úÖ **Type Safety:** Type hints completos

---

## LangChain Expression Language (LCEL)

### O que √© LCEL?

**LCEL** √© uma sintaxe declarativa para criar chains no LangChain. Usa o operador `|` (pipe) para conectar opera√ß√µes, similar ao pipe do Unix.

### Sintaxe B√°sica

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq

# Criar chain usando LCEL
chain = ChatPromptTemplate.from_template("Diga: {input}") | ChatGroq()

# Invocar chain
result = chain.invoke({"input": "Ol√°!"})
```

### Componentes B√°sicos

1. **Prompts:** `ChatPromptTemplate`, `PromptTemplate`
2. **LLMs:** `ChatGroq`, `ChatGoogleGenerativeAI`, `ChatAnthropic`
3. **Parsers:** `StrOutputParser`, `JsonOutputParser`
4. **Runnables:** Qualquer objeto que implementa interface `Runnable`

---

## Chains Sequenciais

### Conceito

Chains sequenciais executam opera√ß√µes uma ap√≥s a outra, passando o resultado de uma para a pr√≥xima.

### Exemplo B√°sico

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_groq import ChatGroq

# Criar chain sequencial
chain = (
    ChatPromptTemplate.from_template("Resuma: {text}")
    | ChatGroq(model="llama-3.1-8b-instant")
    | StrOutputParser()
)

# Usar chain
result = chain.invoke({"text": "Python √© uma linguagem de programa√ß√£o..."})
print(result)
```

### Fluxo de Dados

```
Input ‚Üí Prompt Template ‚Üí LLM ‚Üí Parser ‚Üí Output
```

### Exemplo com M√∫ltiplas Opera√ß√µes

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
from langchain_groq import ChatGroq

# Chain que: gera conte√∫do ‚Üí formata
generate_chain = (
    ChatPromptTemplate.from_template("Gere um par√°grafo sobre {topic}")
    | ChatGroq(model="llama-3.1-8b-instant")
    | StrOutputParser()  # Retorna uma STRING
)

format_chain = (
    ChatPromptTemplate.from_template("Formate este texto em markdown:\n\n{text}")
    | ChatGroq(model="llama-3.1-8b-instant")
    | StrOutputParser()
)

# Combinar chains CORRETAMENTE
# ‚ö†Ô∏è IMPORTANTE: generate_chain retorna string, mas format_chain espera dict com "text"
# Por isso precisamos converter a string em um dicion√°rio
full_chain = (
    generate_chain 
    | RunnableLambda(lambda x: {"text": x})  # Converte string ‚Üí dict
    | format_chain
)

result = full_chain.invoke({"topic": "Intelig√™ncia Artificial"})
print(result)
```

**Explica√ß√£o:**
- `generate_chain` retorna uma **string** (por causa do `StrOutputParser()`)
- `format_chain` espera um **dicion√°rio** com a chave `"text"` (porque o template usa `{text}`)
- `RunnableLambda(lambda x: {"text": x})` converte a string em um dicion√°rio compat√≠vel

---

## Chains Condicionais

### Conceito

Chains condicionais executam diferentes opera√ß√µes baseadas em condi√ß√µes ou no conte√∫do do input.

### Usando RunnableBranch

```python
from langchain_core.runnables import RunnableBranch
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq
from langchain_core.output_parsers import StrOutputParser

# Definir diferentes chains baseadas em condi√ß√£o
short_chain = (
    ChatPromptTemplate.from_template("Resposta curta: {input}")
    | ChatGroq(model="llama-3.1-8b-instant")
    | StrOutputParser()
)

long_chain = (
    ChatPromptTemplate.from_template("Resposta detalhada: {input}")
    | ChatGroq(model="llama-3.1-8b-instant")
    | StrOutputParser()
)

# Fun√ß√£o para decidir qual chain usar
def route(input_dict):
    text = input_dict.get("input", "")
    if len(text) < 50:
        return "short"
    return "long"

# Criar chain condicional
conditional_chain = RunnableBranch(
    (lambda x: len(x.get("input", "")) < 50, short_chain),
    long_chain
)

result = conditional_chain.invoke({"input": "Explique Python"})
```

### Usando RunnableLambda

```python
from langchain_core.runnables import RunnableLambda
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq

# Chain que decide qual LLM usar baseado no idioma
def choose_llm(input_dict):
    language = input_dict.get("language", "en")
    if language == "pt":
        return ChatGroq(model="llama-3.1-8b-instant")
    else:
        return ChatGroq(model="mixtral-8x7b-32768")

chain = (
    ChatPromptTemplate.from_template("{input}")
    | RunnableLambda(choose_llm)
)

result = chain.invoke({"input": "Ol√°!", "language": "pt"})
```

---

## Chains Paralelas

### Conceito

Chains paralelas executam m√∫ltiplas opera√ß√µes simultaneamente e combinam os resultados.

### Usando RunnableParallel

```python
from langchain_core.runnables import RunnableParallel
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq
from langchain_core.output_parsers import StrOutputParser

# Criar m√∫ltiplas chains
sentiment_chain = (
    ChatPromptTemplate.from_template("Analise o sentimento: {text}")
    | ChatGroq(model="llama-3.1-8b-instant")
    | StrOutputParser()
)

summary_chain = (
    ChatPromptTemplate.from_template("Resuma: {text}")
    | ChatGroq(model="llama-3.1-8b-instant")
    | StrOutputParser()
)

keywords_chain = (
    ChatPromptTemplate.from_template("Extraia palavras-chave: {text}")
    | ChatGroq(model="llama-3.1-8b-instant")
    | StrOutputParser()
)

# Executar em paralelo
parallel_chain = RunnableParallel({
    "sentiment": sentiment_chain,
    "summary": summary_chain,
    "keywords": keywords_chain
})

result = parallel_chain.invoke({"text": "Python √© incr√≠vel!"})
print(result)
# {
#   "sentiment": "positivo",
#   "summary": "Texto sobre Python...",
#   "keywords": "Python, programa√ß√£o, linguagem"
# }
```

### Vantagens

- ‚ö° **Performance:** Executa opera√ß√µes simultaneamente
- üîÑ **Efici√™ncia:** Reduz tempo total de execu√ß√£o
- üìä **Flexibilidade:** Combina m√∫ltiplas an√°lises

---

## Composi√ß√£o de Chains

### Conceito

Chains podem ser compostas em outras chains, criando hierarquias complexas.

### Exemplo Pr√°tico

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableParallel, RunnableBranch
from langchain_groq import ChatGroq
from langchain_core.output_parsers import StrOutputParser

# Chain 1: Gerar conte√∫do
generate_chain = (
    ChatPromptTemplate.from_template("Gere conte√∫do sobre {topic}")
    | ChatGroq(model="llama-3.1-8b-instant")
    | StrOutputParser()
)

# Chain 2: Revisar conte√∫do
review_chain = (
    ChatPromptTemplate.from_template("Revise este texto: {text}")
    | ChatGroq(model="llama-3.1-8b-instant")
    | StrOutputParser()
)

# Chain 3: Formatar
format_chain = (
    ChatPromptTemplate.from_template("Formate em markdown: {text}")
    | ChatGroq(model="llama-3.1-8b-instant")
    | StrOutputParser()
)

# Combinar todas as chains
# ‚ö†Ô∏è IMPORTANTE: generate_chain retorna string, mas as outras chains esperam dict com "text"
from langchain_core.runnables import RunnablePassthrough

content_pipeline = (
    generate_chain
    | {"text": RunnablePassthrough()}  # Converte string ‚Üí dict com chave "text"
    | RunnableParallel({
        "reviewed": review_chain,
        "formatted": format_chain
    })
)

result = content_pipeline.invoke({"topic": "IA Generativa"})
```

---

## Streaming com Chains

### Conceito

Chains suportam streaming nativo, permitindo receber respostas incrementalmente.

### Exemplo de Streaming

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq

chain = (
    ChatPromptTemplate.from_template("Conte uma hist√≥ria sobre {topic}")
    | ChatGroq(model="llama-3.1-8b-instant", streaming=True)
)

# Stream de resposta
for chunk in chain.stream({"topic": "Python"}):
    print(chunk.content, end="", flush=True)
```

### Vantagens do Streaming

- ‚ö° **UX melhor:** Usu√°rio v√™ resposta em tempo real
- üéØ **Feedback imediato:** N√£o precisa esperar resposta completa
- üí° **Efici√™ncia:** Processa enquanto recebe

---

## Boas Pr√°ticas

### 1. Nomear Chains Claramente

```python
# ‚úÖ Bom
content_generation_chain = prompt | llm | parser

# ‚ùå Ruim
chain1 = prompt | llm | parser
```

### 2. Documentar Chains Complexas

```python
"""
Chain que gera conte√∫do, revisa e formata.

Fluxo:
1. Gera conte√∫do baseado em t√≥pico
2. Revisa conte√∫do gerado
3. Formata em markdown
"""
content_pipeline = generate_chain | review_chain | format_chain
```

### 3. Reutilizar Chains

```python
# Criar chain reutiliz√°vel
base_chain = prompt_template | llm | parser

# Usar em diferentes contextos
chain_a = base_chain | formatter
chain_b = base_chain | translator
```

### 4. Tratamento de Erros

```python
from langchain_core.runnables import RunnableLambda

def safe_invoke(chain):
    try:
        return chain.invoke(input)
    except Exception as e:
        return {"error": str(e)}

safe_chain = RunnableLambda(safe_invoke)
```

### 5. Testar Chains Incrementalmente

```python
# Testar cada parte separadamente
prompt_result = prompt_template.invoke({"input": "test"})
llm_result = llm.invoke(prompt_result)
parser_result = parser.invoke(llm_result)

# Depois testar chain completa
full_result = chain.invoke({"input": "test"})
```

---

## üìö Recursos Adicionais

- [LangChain Expression Language Docs](https://python.langchain.com/docs/expression_language/)
- [LCEL Get Started](https://python.langchain.com/docs/expression_language/get_started)
- [Runnable Interface](https://python.langchain.com/docs/expression_language/interface)
- [Streaming Guide](https://python.langchain.com/docs/expression_language/streaming)

---

## üéØ Pr√≥ximos Passos

Agora que voc√™ entendeu chains b√°sicas, voc√™ est√° pronto para:
- Dia 3: RAG b√°sico (usar√° chains para buscar e gerar)
- Dia 4: RAG avan√ßado (chains com vector databases)
- Dia 5: Agents (chains aut√¥nomas que decidem a√ß√µes)

---

**√öltima atualiza√ß√£o:** 2 Dez 2025  
**Refer√™ncias:** Baseado em documenta√ß√£o LangChain de julho de 2025 em diante

