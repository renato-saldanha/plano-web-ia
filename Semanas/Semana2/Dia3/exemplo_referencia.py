#!/usr/bin/env python3
"""
Exemplo de Refer√™ncia: RAG B√°sico com LangChain

Este arquivo demonstra como criar um sistema RAG b√°sico usando LangChain.
RAG (Retrieval-Augmented Generation) combina busca em documentos com gera√ß√£o de resposta.

Uso:
    python exemplo_referencia.py
"""

import os
from dotenv import load_dotenv  # type: ignore
from langchain_community.document_loaders import TextLoader  # type: ignore
from langchain_text_splitters import RecursiveCharacterTextSplitter  # type: ignore
from langchain_community.retrievers import BM25Retriever  # type: ignore
from langchain_core.output_parsers import StrOutputParser  # type: ignore
from langchain_core.runnables import RunnablePassthrough  # type: ignore
from langchain_groq import ChatGroq  # type: ignore
from langchain_core.prompts import ChatPromptTemplate  # type: ignore

# ============================================================================
# SE√á√ÉO 1: CONFIGURA√á√ÉO
# ============================================================================
load_dotenv()

# Criar inst√¢ncia do LLM (reutiliz√°vel)
llm = ChatGroq(
    model="llama-3.1-8b-instant",
    temperature=0,
    groq_api_key=os.getenv("GROQ_API_KEY")
)

# ============================================================================
# SE√á√ÉO 2: CRIAR DOCUMENTO DE EXEMPLO
# ============================================================================
# Em produ√ß√£o, voc√™ carregaria documentos reais. Aqui criamos um exemplo.

print("=" * 60)
print("EXEMPLO: Sistema RAG B√°sico")
print("=" * 60)

# Criar arquivo de exemplo com informa√ß√µes sobre Python
documento_exemplo = """
Python √© uma linguagem de programa√ß√£o de alto n√≠vel criada por Guido van Rossum em 1991.
A linguagem foi projetada com foco na legibilidade do c√≥digo e produtividade do programador.

Python suporta m√∫ltiplos paradigmas de programa√ß√£o, incluindo programa√ß√£o orientada a objetos,
programa√ß√£o imperativa e programa√ß√£o funcional. Possui um sistema de tipos din√¢mico e gerenciamento
autom√°tico de mem√≥ria.

A linguagem √© amplamente usada para desenvolvimento web, ci√™ncia de dados, intelig√™ncia artificial,
automa√ß√£o de tarefas e muito mais. Python tem uma grande comunidade e ecossistema de bibliotecas.

Algumas bibliotecas populares incluem:
- NumPy: Para computa√ß√£o cient√≠fica
- Pandas: Para an√°lise de dados
- Django e Flask: Para desenvolvimento web
- LangChain: Para aplica√ß√µes com IA generativa
"""

# Salvar documento tempor√°rio
arquivo_temp = "documento_exemplo.txt"
with open(arquivo_temp, "w", encoding="utf-8") as f:
    f.write(documento_exemplo)

print(f"‚úÖ Documento criado: {arquivo_temp}\n")

# ============================================================================
# SE√á√ÉO 3: CARREGAR DOCUMENTO
# ============================================================================
# Document Loader: Carrega documentos de diferentes fontes

print("=" * 60)
print("PASSO 1: Carregar Documento")
print("=" * 60)
# PyPDFLoader para PDF
loader = TextLoader(arquivo_temp, encoding="utf-8")
documents = loader.load()

print(f"‚úÖ Documentos carregados: {len(documents)}")
print(
    f"üìÑ Conte√∫do (primeiros 200 caracteres): {documents[0].page_content[:200]}...\n")

# ============================================================================
# SE√á√ÉO 4: DIVIDIR EM CHUNKS
# ============================================================================
# Text Splitter: Divide documentos grandes em chunks menores

print("=" * 60)
print("PASSO 2: Dividir em Chunks")
print("=" * 60)

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=300,      # Tamanho de cada chunk (caracteres)
    chunk_overlap=50,    # Sobreposi√ß√£o entre chunks
    length_function=len,
    separators=["\n\n", "\n", ". ", " ", ""]  # Ordem de separa√ß√£o
)

chunks = text_splitter.split_documents(documents)

print(f"‚úÖ Chunks criados: {len(chunks)}")
for i, chunk in enumerate(chunks, 1):
    print(f"\nüì¶ Chunk {i} ({len(chunk.page_content)} caracteres):")
    print(f"   {chunk.page_content[:100]}...")

# ============================================================================
# SE√á√ÉO 5: CRIAR RETRIEVER
# ============================================================================
# Retriever: Busca chunks relevantes baseado em query

print("\n" + "=" * 60)
print("PASSO 3: Criar Retriever")
print("=" * 60)

retriever = BM25Retriever.from_documents(chunks)
retriever.k = 2  # Retornar top 2 chunks mais relevantes

# Testar busca
query_teste = "Quem criou Python?"
chunks_relevantes = retriever.invoke(query_teste)

print(f"‚úÖ Retriever criado")
print(f"üîç Query de teste: '{query_teste}'")
print(f"üìö Chunks encontrados: {len(chunks_relevantes)}")
for i, chunk in enumerate(chunks_relevantes, 1):
    print(f"\n   Chunk {i}:")
    print(f"   {chunk.page_content[:150]}...")

# ============================================================================
# SE√á√ÉO 6: CRIAR CHAIN RAG COMPLETA
# ============================================================================
# Chain RAG: Combina retriever + LLM para gerar resposta contextualizada
# Usando LCEL (LangChain Expression Language) - abordagem moderna

print("\n" + "=" * 60)
print("PASSO 4: Criar Chain RAG")
print("=" * 60)

# Criar prompt template moderno com ChatPromptTemplate
prompt_template = ChatPromptTemplate.from_messages([
    ("system", "Use as seguintes informa√ß√µes do contexto para responder a pergunta. Se voc√™ n√£o souber a resposta, diga que n√£o sabe. N√£o invente informa√ß√µes."),
    ("human", "Contexto:\n{context}\n\nPergunta: {input}\n\nResposta:")
])

# Criar chain RAG usando LCEL puro (sem fun√ß√µes helper)


def format_docs(docs):
    """Formata documentos em uma string para o contexto"""
    return "\n\n".join(doc.page_content for doc in docs)


qa_chain = (
    {
        "context": retriever | format_docs,
        "input": RunnablePassthrough()
    }
    | prompt_template
    | llm
    | StrOutputParser()
)

print("‚úÖ Chain RAG criada\n")

# ============================================================================
# SE√á√ÉO 7: FAZER PERGUNTAS
# ============================================================================
# Testar sistema RAG com diferentes perguntas

print("=" * 60)
print("PASSO 5: Fazer Perguntas")
print("=" * 60)

perguntas = [
    "Quem criou Python?",
    "Quais s√£o algumas bibliotecas populares do Python?",
    "Para que Python √© usado?",
]

for pergunta in perguntas:
    print(f"\n‚ùì Pergunta: {pergunta}")
    print("-" * 60)

    # LCEL puro retorna apenas a resposta (string)
    resposta = qa_chain.invoke(pergunta)

    # Buscar chunks relevantes separadamente para mostrar fontes
    chunks_relevantes = retriever.invoke(pergunta)

    print(f"üí° Resposta: {resposta}")
    print(f"üìö Fontes usadas: {len(chunks_relevantes)} chunks")

    # Mostrar chunks usados
    for i, doc in enumerate(chunks_relevantes, 1):
        print(f"\n   Fonte {i}:")
        print(f"   {doc.page_content[:100]}...")

# ============================================================================
# SE√á√ÉO 8: LIMPEZA
# ============================================================================
# Remover arquivo tempor√°rio

print("\n" + "=" * 60)
print("Limpeza")
print("=" * 60)

if os.path.exists(arquivo_temp):
    os.remove(arquivo_temp)
    print(f"‚úÖ Arquivo tempor√°rio removido: {arquivo_temp}")

print("\n‚úÖ Exemplo conclu√≠do!")
print("\nüí° Pr√≥ximos passos:")
print("   - Modifique o documento para testar com seus pr√≥prios dados")
print("   - Experimente diferentes tamanhos de chunks")
print("   - Teste com diferentes perguntas")
print("   - Veja como RAG melhora respostas comparado a gera√ß√£o simples")
