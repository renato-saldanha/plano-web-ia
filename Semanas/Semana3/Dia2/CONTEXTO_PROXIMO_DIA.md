# ğŸ¯ Contexto para Construir o Dia 3

## ğŸ“š O que aprendemos hoje (Dia 2)

### Conceitos Principais
- JWT (JSON Web Tokens): estrutura header.payload.signature
- DiferenÃ§a entre access token (curta duraÃ§Ã£o) e refresh token (longa duraÃ§Ã£o)
- Password hashing com bcrypt via passlib
- FastAPI `Depends()` para criar guards de autenticaÃ§Ã£o
- OAuth2PasswordBearer para extrair tokens do header Authorization

### Habilidades Desenvolvidas
- Criar e verificar tokens JWT com python-jose
- Implementar fluxo completo de login/refresh
- Proteger rotas com dependencies
- Hashear senhas de forma segura
- Testar endpoints autenticados com curl/httpie

### CÃ³digo Criado
- `template.py` (ou versÃ£o completa) com:
  - `POST /login` - AutenticaÃ§Ã£o e geraÃ§Ã£o de tokens
  - `POST /refresh` - RenovaÃ§Ã£o de tokens
  - `GET /chat` - Rota protegida
  - FunÃ§Ãµes `create_access_token`, `create_refresh_token`, `verify_token`
  - Dependency `get_current_user`

---

## ğŸ”— Por que o Dia 3 Ã© importante

- Temos API segura, mas `/chat` ainda retorna resposta fixa (placeholder)
- Precisamos integrar LLM real (Claude/GPT) para respostas inteligentes
- Streaming Ã© essencial para UX moderna (estilo ChatGPT)
- Combinar auth + streaming + LLM = API pronta para produÃ§Ã£o

---

## ğŸ¯ O que serÃ¡ feito no Dia 3

### Objetivo Principal
Implementar streaming de respostas com `StreamingResponse` e integrar LLM real (LangChain) no endpoint `/chat` protegido.

### Conceitos que serÃ£o aprendidos
- `StreamingResponse` do FastAPI
- Async generators em Python
- Server-Sent Events (SSE) para streaming
- LangChain com streaming callbacks
- IntegraÃ§Ã£o LLM (Claude/GPT) via API

### Como se relaciona com Dia 2
- Reutiliza toda a estrutura de autenticaÃ§Ã£o JWT
- `/chat` continua protegido, mas agora retorna resposta do LLM
- Adiciona `/api/generate` como novo endpoint de streaming
- MantÃ©m `/login` e `/refresh` sem alteraÃ§Ãµes

---

## ğŸ“‹ Como Construir o Dia 3

### 1. Criar Estrutura BÃ¡sica
```
Dia3/
â”œâ”€â”€ README.md
â”œâ”€â”€ CONTEXTO_AGENTE.md
â”œâ”€â”€ checklist.md
â”œâ”€â”€ journal.md
â”œâ”€â”€ requirements.txt (adicionar langchain, httpx-sse)
â”œâ”€â”€ CONTEXTO_PROXIMO_DIA.md
â”‚
â”œâ”€â”€ template.py (TODOs para streaming)
â”œâ”€â”€ GUIA_APRENDIZADO.md (conceitos de streaming + LLM)
â”œâ”€â”€ exemplo_referencia.py (implementaÃ§Ã£o completa)
â””â”€â”€ exercicios.md (otimizaÃ§Ãµes e variaÃ§Ãµes)
```

### 2. Definir NÃ­vel de Scaffolding
- Streaming Ã© conceito parcialmente conhecido (visto no Dia 1 com `StreamingResponse`)
- LangChain jÃ¡ foi usado na Semana 2
- RecomendaÃ§Ã£o: **NÃ­vel 2** (aplicaÃ§Ã£o em novo contexto)

### 3. Arquivos necessÃ¡rios
- `template.py`: Estrutura com TODOs para:
  - Async generator que gera chunks
  - Endpoint `/api/generate` com StreamingResponse
  - IntegraÃ§Ã£o LangChain com streaming callback
  - Modificar `/chat` para usar LLM real
- `GUIA_APRENDIZADO.md`: 
  - SeÃ§Ã£o 1: StreamingResponse e async generators
  - SeÃ§Ã£o 2: Server-Sent Events (SSE)
  - SeÃ§Ã£o 3: LangChain streaming com callbacks
  - SeÃ§Ã£o 4: ImplementaÃ§Ã£o passo a passo
- `exemplo_referencia.py`: CÃ³digo completo funcionando
- `exercicios.md`: 
  - ExercÃ­cio 1: Adicionar typing indicator
  - ExercÃ­cio 2: Implementar cancelamento de stream
  - ExercÃ­cio 3: Rate limiting por usuÃ¡rio
  - ExercÃ­cio 4: Cache de respostas

### 4. Endpoints a implementar no Dia 3
```
POST /api/generate
- Body: {"prompt": "...", "model": "gpt-3.5-turbo"}
- Header: Authorization: Bearer <token>
- Response: text/event-stream (SSE)

POST /chat (modificado)
- Body: {"message": "...", "stream": true/false}
- Header: Authorization: Bearer <token>
- Response: Streaming ou JSON
```

### 5. Checklist sugerido
- PreparaÃ§Ã£o (5min): Revisar README, instalar deps (langchain, httpx-sse)
- Leitura (20min): GUIA_APRENDIZADO seÃ§Ãµes 1-3
- ConstruÃ§Ã£o (90min):
  - Implementar async generator bÃ¡sico (20min)
  - Criar endpoint `/api/generate` com SSE (30min)
  - Integrar LangChain com streaming callback (25min)
  - Modificar `/chat` para usar LLM (15min)
- ConsolidaÃ§Ã£o (25min): Testar streaming no navegador e curl
- Registro (20min): Journal e CONTEXTO_PROXIMO_DIA

---

## ğŸ“š Recursos de PreparaÃ§Ã£o

### O que revisar antes de comeÃ§ar:
- [ ] FastAPI StreamingResponse: https://fastapi.tiangolo.com/advanced/custom-response/#streamingresponse
- [ ] Async generators em Python: https://peps.python.org/pep-0525/
- [ ] LangChain Streaming: https://python.langchain.com/docs/how_to/streaming/
- [ ] Server-Sent Events: https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events

### Conceitos prÃ©-requisitos:
- Async/await em Python (usado no Dia 1-2)
- StreamingResponse bÃ¡sico (visto no Dia 1)
- LangChain bÃ¡sico (Semana 2)
- JWT Authentication (Dia 2)

### DependÃªncias adicionais:
```
langchain>=0.1.0
langchain-openai>=0.0.5  # ou langchain-anthropic
httpx>=0.25.0
sse-starlette>=1.8.0
```

---

## ğŸ’¡ Dicas Importantes

1. **Copiar base do Dia 2**: Use o `exemplo_referencia.py` do Dia 2 como ponto de partida
2. **Testar streaming no navegador**: Use `/docs` do FastAPI ou pÃ¡gina HTML simples
3. **VariÃ¡veis de ambiente**: Adicionar `OPENAI_API_KEY` ou `ANTHROPIC_API_KEY`
4. **Se tempo exceder 160min**: Mover exercÃ­cios extras para Dia 4

---

## ğŸ” Exemplo de cÃ³digo para Dia 3

### Async Generator bÃ¡sico
```python
async def generate_response(prompt: str):
    """Async generator que simula streaming."""
    words = prompt.split()
    for word in words:
        yield f"data: {word}\n\n"
        await asyncio.sleep(0.1)
    yield "data: [DONE]\n\n"
```

### StreamingResponse com SSE
```python
from fastapi.responses import StreamingResponse

@app.post("/api/generate")
async def generate(
    request: GenerateRequest,
    current_user: dict = Depends(get_current_user)
):
    return StreamingResponse(
        generate_response(request.prompt),
        media_type="text/event-stream"
    )
```

### LangChain com streaming callback
```python
from langchain_openai import ChatOpenAI
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    streaming=True,
    callbacks=[StreamingStdOutCallbackHandler()]
)
```

---

**Ãšltima atualizaÃ§Ã£o:** 10 Dez 2025  
**Status:** ğŸŸ¡ Pronto como briefing para o Dia 3


